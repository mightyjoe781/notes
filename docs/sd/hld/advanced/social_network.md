# Social Network

## Instagram's Year 1 Architecture

![](assets/Pasted%20image%2020250914101946.png)

Facebook made PHP MySQL famous -> everyone did that 
Instagram made above arch famous ... everyone started doing it.

Why famous ? 1 year, 14 million, 3 engineers.
## How CDN works ?

Say, you origin is https://smk.minetest.in/ and there is a path that returns some response. *JSON, Bytes, Image, HTML, Video, anything*

https://smk.minetest.in/logo.png

CDN has its own domain, say cloudflare.net

![](assets/Pasted%20image%2020250914104236.png)

User hitting : https://smk.cloudflare.net/logo.png, goes to CDN, which finds the origin for `smk.cloudflare.net` it then forwards request to origin server

https://smk.minetest.in/logo.png (cache it and returns)

## Uploading photos at scale

Requirements 

- 5 M photos upload a day

Brainstorm : Storage, data flow, separation of concern, privacy, extensibility, optimization

Basics

- where to store image ? *S3*
- Uploading the image through API Servers ?

![](assets/Pasted%20image%2020250914132806.png)

Bad Idea ! Twice the bandwidth is consumed.

- storage decision ? sharded relational DB
- serving images ? directly through S3
- serving images quickly ? use CDN
    - caching of images on CDN
    - security out of the box
    - geographical distribution

![](assets/Pasted%20image%2020250914141234.png)

Upload Photos

- user A talks to *Image Service* to prepare for upload
- Image service generates a *random image ID* and talks to S3 to create a signed-url to allow *anyone* to upload on the path. `s3://photos/<user_id>/<random_photo_id>.jpg`
- user A *directly* uploads the photo to s3 on the signed URL and the file sits at the specified S3 path.

Publish Photos

User keeps track of the random image id it got from image it uses this to create the entry in posts table

- LinkedIn also does this
- CDNs also do this

![](assets/Pasted%20image%2020250914141734.png)

Post service can also validate that the *image_id* provided in the request belongs to the same user or not.

![](assets/Pasted%20image%2020250914141913.png)

#### Complete Architecture

![](assets/Pasted%20image%2020250914143049.png)

- user A uploads photo using Image Service
- user A posts the photo
    - creates an entry in post table
- user B visits A's profile
- GET /users/A/posts

NOTE: url will be Dynamically generated by backend. e.g. https://instacdn.net/A/1234.png

The image urls are rendered in `< IMG/>` tag
The photo are loaded from "instacdn"  and are rendered

### Privacy

Are instagram's private photo really private ? *NO*
Every photo URL has signature (timed) attached in the URL

`https://instacdn.net/ul/1729_4275.jpg?ig_cache_key=...&oh=...&oe=...&nc_sid=...`

when the URL is rendered through IMG tag, the request goes to CDN, CDN validate the request using the attached keys and if certs are valid and not expired, *it returns the image* otherwise it returns bad url.

The URL is short lived because certs are short-lived.

### Image Optimisations

Users belong to different geographics, different network bandwidth different mobile device, different processing power.
So sending 5 MB photo uploaded by your favourite celeb to all the followers is a very bad idea. 

So we should have different resolutions off the photos ready to serve to the users depending on their *state*

- instead of building our image optimizer service
- we can leverage the CDN features that are provided out of box.

`https://instacdn.net/ul/1729_4275.jpg?w=360`

Here last `w` sets the width of the photo and transforms it before sending to user, and caches as well.


## HashTag Service

![](assets/Pasted%20image%2020250914161209.png)

- millions of hashtag
- assume there is a service that notifies us when it generates *top* photos for a hashtag.

### Input to our system ?

- event when post is published
- event when *top* photos are evaluated for a hashtag.

![](assets/Pasted%20image%2020250914163301.png)

Key Requirement : *Superfast response times*
One request : `/hashtag/<tag>` 

```json
{
    "tag": "...",
    "total_photos": "...",
    "top_100_photos" : [
        "<photo_content>" // "post_1",
        "<photo_content>" // "post_2"
    ]
}
```

Anything and every thing we need should be present in the payload itself. So rather than storing *post_id* we store the actual content.

- returned in a single response
- pre-computed and pre-evaluated

### High Volume Counting

*Batching -> Partitioning*

Main HashTag API servers won't count, worker nodes batch and update

![](assets/Pasted%20image%2020250914164025.png)

A good way to optimize systems is to identify *READ PATH* and *WRITE PATH* and optimize them independently.

Key Value based access for a key (*hashtag*) get the value (details)

Write PATH Optimization

- ingestion in kafka

Requirements from storage ?

- partial updates

Challenge : POST_PUBLISH topic is partitioned by *post_id* or *user_id*. But for our own batching and counting to work, we need an event per hashing.
If a post has 8 hashtags we would need one event for each hashtag so that we can count and batch *efficiently*

So, we have to write an adapter that

- reads *POST_PUBLISH* events from kafka
- extracts all hashtags from the post
- creates `n` new events on topic *POST_HASHTAG* for n hashtags partitioned by hashtag.


![](assets/Pasted%20image%2020250914164738.png)

Now Including the top post service in above diagram

![](assets/Pasted%20image%2020250914165805.png)


Key Takeaways :

- Kafka as a glue
- Adapter Pattern
- Effective Batching & Counting
- READ/WRITE Path optimizations