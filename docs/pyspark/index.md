# Pyspark

Credits : Following notes are learnings from *Spark: The Definitive Guide by Bill Chambers and Matei Zaharia*

- Overview of Big Data and Spark
   1. [What is Apache Spark ?](notes/ch1.md)
   2. [A Gentle Introduction to Spark](notes/ch2.md)
   3. [A Tour of Sparkâ€™s Toolset](notes/ch3.md)
- Structured APIs - DataFrames, SQL And Datasets
   1. [Structured API Overview](notes/ch4.md)
   2. [Basic Structured Operations](notes/ch5.md)
   3. [Working With Different Types of Data](notes/ch6.md)
   4. [Aggregations](notes/ch7.md)
   5. [Joins](notes/ch8.md)
   6. [Data Sources](notes/ch9.md)
   7. [Spark SQL](notes/ch10.md)
   8. [Datasets](notes/ch11.md)

Till this its probably enough to learn 80% of pyspark and people can head dive into the pyspark easily.

- Low-Level APIs
  1. Resilient Distributed Datasets
  2. Advanced RDDs
  3. Distributed Shared Variables

This shoud be performed practically with a running spark cluster and probably book is best place to read this.

- Production Applications
  1. How Spark Runs on a Cluster
  2. Developing Spark Applications
  3. Deploying Spark
  4. Monitoring and Debugging
  5. Performance Tuning

You should take a look at *Apache Flink* as well for Streaming Solutions.

- Streaming
  1. [Stream Processing Fundamentals](notes/ch20.md)
  2. [Structured Streaming Basics](notes/ch21.md)
  3. [Event Time And Stateful Processing](notes/ch22.md)
  4. [Structured Streaming in Production](notes/ch23.md)

For Running Machine Learning Workloads on Spark. There is a dedicate guide for ML on the site.

- Advanced Analytics and Machine Learning
  1. Advanced. Analytics and Machine Learning Overview
  1. Preprocessing and Feature Engineering
  1. Classification
  1. Regression
  1. Recommendation
  1. Unsupervised Learning
  1. Graph Analytics
  1. Deep Learning
- Ecosystem
  1. Language Specifics: Python (pyspark) and R (SparkR and Sparklyr
  1. Ecosystem and Community

## Books

- [Learning Spark 2.0](https://pages.databricks.com/rs/094-YMS-629/images/LearningSpark2.0.pdf)