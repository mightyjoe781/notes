# Graph Analytics

- *Graph analytics* is the process of analyzing these relationships.

- Graphs are a natural way of describing relationships and many different  problem sets, and Spark provides several ways of working in this analytics paradigm.

- Spark has long contained an RDD-based library for performing graph  processing: GraphX. This provided a very low-level interface that was  extremely powerful, but just like RDDs, wasn’t easy to use or optimize.

- However, some of the developers of Spark (including some of the original authors of GraphX) have recently created a next-generation graph analytics library on Spark: GraphFrames.

[GraphFrames](http://graphframes.github.io/index.html) is currently [available as a Spark package](http://spark-packages.org/package/graphframes/graphframes), an external package that you need to load when you start up your Spark  application, but may be merged into the core of Spark in the future. For the most part, there should be little difference in performance between the two (except for a huge user experience improvement in GraphFrames). There is some small overhead when using GraphFrames, but for the most  part it tries to call down to GraphX where appropriate; and for most,  the user experience gains greatly outweigh this minor overhead.

````shell
./bin/spark-shell --packages graphframes:graphframes:0.5.0-spark2.2-s_2.11
````

````python
bikeStations = spark.read.option("header","true")\
  .csv("/data/bike-data/201508_station_data.csv")
tripData = spark.read.option("header","true")\
  .csv("/data/bike-data/201508_trip_data.csv")
````

## Building a Graph

- Example building a directed graph. graph will point from source to destination location

````python
stationVertices = bikeStations.withColumnRenamed("name", "id").distinct()
tripEdges = tripData\
  .withColumnRenamed("Start Station", "src")\
  .withColumnRenamed("End Station", "dst")
````

````python
# building graphframe object
from graphframes import GraphFrame
stationGraph = GraphFrame(stationVertices, tripEdges)
stationGraph.cache()
````

````python
# in Python
print "Total Number of Stations: " + str(stationGraph.vertices.count())
print "Total Number of Trips in Graph: " + str(stationGraph.edges.count())
print "Total Number of Trips in Original Data: " + str(tripData.count())

# Total Number of Stations: 70
# Total Number of Trips in Graph: 354152
# Total Number of Trips in Original Data: 354152
````

## Querying a Graph

````python
from pyspark.sql.functions import desc
stationGraph.edges.groupBy("src", "dst").count().orderBy(desc("count")).show(10)

+--------------------+--------------------+-----+
|                 src|                 dst|count|
+--------------------+--------------------+-----+
|San Francisco Cal...|     Townsend at 7th| 3748|
|Harry Bridges Pla...|Embarcadero at Sa...| 3145|
...
|     Townsend at 7th|San Francisco Cal...| 2192|
|Temporary Transba...|San Francisco Cal...| 2184|
+--------------------+--------------------+-----+

# Filtering by any valid DF Expression
stationGraph.edges\
  .where("src = 'Townsend at 7th' OR dst = 'Townsend at 7th'")\
  .groupBy("src", "dst").count()\
  .orderBy(desc("count"))\
  .show(10)

+--------------------+--------------------+-----+
|                 src|                 dst|count|
+--------------------+--------------------+-----+
|San Francisco Cal...|     Townsend at 7th| 3748|
|     Townsend at 7th|San Francisco Cal...| 2734|
...
|   Steuart at Market|     Townsend at 7th|  746|
|     Townsend at 7th|Temporary Transba...|  740|
+--------------------+--------------------+-----+
````

### Subgraphs

*Subgraphs* are just smaller graphs within the larger one. We saw in the last section how we can query a given set of edges and vertices.

````python
townAnd7thEdges = stationGraph.edges\
  .where("src = 'Townsend at 7th' OR dst = 'Townsend at 7th'")
subgraph = GraphFrame(stationGraph.vertices, townAnd7thEdges)
````

## Motif Finding

*Motifs* are a way of expresssing structural patterns in a graph. When we specify a  motif, we are querying for patterns in the data instead of actual data. In GraphFrames, we specify our query in a domain-specific language  similar to Neo4J’s Cypher language. This language lets us specify  combinations of vertices and edges and assign then names.

For example, if we want to specify that a given vertex `a` connects to another vertex `b` through an edge `ab`, we would specify `(a)-[ab]->(b)`. The names inside parentheses or brackets do not signify values but  instead what the columns for matching vertices and edges should be named in the resulting DataFrame. We can omit the names (e.g., `(a)-[]->()`) if we do not intend to query the resulting values.

````python
motifs = stationGraph.find("(a)-[ab]->(b); (b)-[bc]->(c); (c)-[ca]->(a)")
````

````python
from pyspark.sql.functions import expr
motifs.selectExpr("*",
    "to_timestamp(ab.`Start Date`, 'MM/dd/yyyy HH:mm') as abStart",
    "to_timestamp(bc.`Start Date`, 'MM/dd/yyyy HH:mm') as bcStart",
    "to_timestamp(ca.`Start Date`, 'MM/dd/yyyy HH:mm') as caStart")\
  .where("ca.`Bike #` = bc.`Bike #`").where("ab.`Bike #` = bc.`Bike #`")\
  .where("a.id != b.id").where("b.id != c.id")\
  .where("abStart < bcStart").where("bcStart < caStart")\
  .orderBy(expr("cast(caStart as long) - cast(abStart as long)"))\
  .selectExpr("a.id", "b.id", "c.id", "ab.`Start Date`", "ca.`End Date`")
  .limit(1).show(1, False)
````

## Graph Algorithms

### PageRank

````python
from pyspark.sql.functions import desc
ranks = stationGraph.pageRank(resetProbability=0.15, maxIter=10)
ranks.vertices.orderBy(desc("pagerank")).select("id", "pagerank").show(10)

+--------------------+------------------+
|                  id|          pagerank|
+--------------------+------------------+
|San Jose Diridon ...| 4.051504835989922|
|San Francisco Cal...|3.3511832964279518|
...
|     Townsend at 7th| 1.568456580534273|
|Embarcadero at Sa...|1.5414242087749768|
+--------------------+------------------+
````

### In-Degree and Out-Degree Metric

- used in context of social networking, follow and followers

````python
inDeg = stationGraph.inDegrees
inDeg.orderBy(desc("inDegree")).show(5, False)

+----------------------------------------+--------+
|id                                      |inDegree|
+----------------------------------------+--------+
|San Francisco Caltrain (Townsend at 4th)|34810   |
|San Francisco Caltrain 2 (330 Townsend) |22523   |
|Harry Bridges Plaza (Ferry Building)    |17810   |
|2nd at Townsend                         |15463   |
|Townsend at 7th                         |15422   |
+----------------------------------------+--------+

# outdegree
outDeg = stationGraph.outDegrees
outDeg.orderBy(desc("outDegree")).show(5, False)

+---------------------------------------------+---------+
|id                                           |outDegree|
+---------------------------------------------+---------+
|San Francisco Caltrain (Townsend at 4th)     |26304    |
|San Francisco Caltrain 2 (330 Townsend)      |21758    |
|Harry Bridges Plaza (Ferry Building)         |17255    |
|Temporary Transbay Terminal (Howard at Beale)|14436    |
|Embarcadero at Sansome                       |14158    |
+---------------------------------------------+---------+
````

The ratio of these two values is an interesting metric to look at. A  higher ratio value will tell us where a large number of trips end (but  rarely begin), while a lower value tells us where trips often begin (but infrequently end):

````python
degreeRatio = inDeg.join(outDeg, "id")\
  .selectExpr("id", "double(inDegree)/double(outDegree) as degreeRatio")
degreeRatio.orderBy(desc("degreeRatio")).show(10, False)
degreeRatio.orderBy("degreeRatio").show(10, False)
````

### BFS

We can specify the maximum of edges to follow with the `maxPathLength`, and we can also specify an `edgeFilter` to filter out edges that do not meet a requirement, like trips during nonbusiness hours.

````python
stationGraph.bfs(fromExpr="id = 'Townsend at 7th'",
  toExpr="id = 'Spear at Folsom'", maxPathLength=2).show(10)

+--------------------+--------------------+--------------------+
|                from|                  e0|                  to|
+--------------------+--------------------+--------------------+
|[65,Townsend at 7...|[913371,663,8/31/...|[49,Spear at Fols...|
|[65,Townsend at 7...|[913265,658,8/31/...|[49,Spear at Fols...|
...
|[65,Townsend at 7...|[903375,850,8/24/...|[49,Spear at Fols...|
|[65,Townsend at 7...|[899944,910,8/21/...|[49,Spear at Fols...|
+--------------------+--------------------+--------------------+
````

### Connected Components

- A *connected component* defines an (undirected) subgraph that has connections to itself but does not connect to the greater graph

````python
spark.sparkContext.setCheckpointDir("/tmp/checkpoints")

minGraph = GraphFrame(stationVertices, tripEdges.sample(False, 0.1))
cc = minGraph.connectedComponents()

cc.where("component != 0").show()

+----------+------------------+---------+-----------+---------+------------+-----
|station_id|                id|      lat|       long|dockcount|    landmark|in...
+----------+------------------+---------+-----------+---------+------------+-----
|        47|   Post at Kearney|37.788975|-122.403452|       19|San Franc...|  ...
|        46|Washington at K...|37.795425|-122.404767|       15|San Franc...|  ...
+----------+------------------+---------+-----------+---------+------------+-----
````

### Strongly Connected Components

- A strongly connected component is a subgraph that has paths between all pairs of vertices inside it.
- NOTE: takes directionality into account

````python
scc = minGraph.stronglyConnectedComponents(maxIter=3)
scc.groupBy("component").count().show()
````

### Advanced Tasks

This is just a short selection of some of the features of GraphFrames.  The GraphFrames library also includes features such as writing your own  algorithms via a message-passing interface, triangle counting, and  converting to and from GraphX. You can find more information in the  GraphFrames documentation.